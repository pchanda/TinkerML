{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<torch.cuda.device object at 0x7fdb080c0128>\n",
      "1\n",
      "GeForce GTX 1050 Ti with Max-Q Design\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We will read 2 graphs, store them in netwrokx objects.\n",
    "Then we will encode each graph to a vector.\n",
    "'''\n",
    "\n",
    "import networkx as nx\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def check_if_gpu_is_available():\n",
    "    print(torch.cuda.current_device())\n",
    "    print(torch.cuda.device(0))\n",
    "    print(torch.cuda.device_count())\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(torch.cuda.is_available())\n",
    "\n",
    "CUDA=0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(CUDA)\n",
    "\n",
    "check_if_gpu_is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the graphs read ------------------>\n",
      "graph  0 , no of nodes: 4\n",
      "adjacency_list:\n",
      "0 = {1: {'feature': array([1., 0., 0., 0.])}, 2: {'feature': array([0., 1., 0., 0.])}}\n",
      "1 = {0: {'feature': array([1., 0., 0., 0.])}, 2: {'feature': array([0., 0., 1., 0.])}}\n",
      "2 = {0: {'feature': array([0., 1., 0., 0.])}, 1: {'feature': array([0., 0., 1., 0.])}, 3: {'feature': array([0., 0., 0., 1.])}}\n",
      "3 = {2: {'feature': array([0., 0., 0., 1.])}}\n",
      "adjacency_matrix = \n",
      " [[0. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 1. 0. 1.]\n",
      " [0. 0. 1. 0.]]\n",
      "node 0 features= [0. 1. 2.] label= 10\n",
      "node 1 features= [0.1 1.1 2.1] label= 11\n",
      "node 2 features= [0.2 1.2 2.2] label= 12\n",
      "node 3 features= [0.3 1.3 2.3] label= 13\n",
      "edge (0, 1) features= [1. 0. 0. 0.]\n",
      "edge (0, 2) features= [0. 1. 0. 0.]\n",
      "edge (1, 2) features= [0. 0. 1. 0.]\n",
      "edge (2, 3) features= [0. 0. 0. 1.]\n",
      "----------------------------------------\n",
      "graph  1 , no of nodes: 3\n",
      "adjacency_list:\n",
      "4 = {5: {'feature': array([1., 0., 0., 0.])}}\n",
      "5 = {4: {'feature': array([1., 0., 0., 0.])}, 6: {'feature': array([0., 1., 0., 0.])}}\n",
      "6 = {5: {'feature': array([0., 1., 0., 0.])}}\n",
      "adjacency_matrix = \n",
      " [[0. 1. 0.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "node 4 features= [0.4 1.4 2.4] label= 24\n",
      "node 5 features= [0.5 1.5 2.5] label= 25\n",
      "node 6 features= [0.6 1.6 2.6] label= 26\n",
      "edge (4, 5) features= [1. 0. 0. 0.]\n",
      "edge (5, 6) features= [0. 1. 0. 0.]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Create and empty graph and populate it by reading the input files.\n",
    "G = nx.Graph() #create an empty graph.\n",
    "filepath = './data_graph_encoding/'\n",
    "\n",
    "#list of edges.\n",
    "data_edge_list = np.loadtxt(os.path.join(filepath,'edges.txt'), delimiter=',').astype(int) \n",
    "\n",
    "#features for each node\n",
    "data_node_features = np.loadtxt(os.path.join(filepath,'node_features.txt'), delimiter=',')\n",
    "\n",
    "#labels for each node\n",
    "data_node_labels = np.loadtxt(os.path.join(filepath,'node_labels.txt'), delimiter=',').astype(int)\n",
    "\n",
    "#features for each edge\n",
    "data_edge_features = np.loadtxt(os.path.join(filepath,'edge_features.txt'), delimiter=',')\n",
    "\n",
    "#1 line = a label for each graph. \n",
    "data_graph_labels = np.loadtxt(os.path.join(filepath,'graph_labels.txt'), delimiter=',').astype(int)\n",
    "\n",
    "#which nodes belong to which graph.\n",
    "data_graph_indicator = np.loadtxt(os.path.join(filepath,'graph_indicators.txt'), delimiter=',').astype(int)\n",
    "\n",
    "data_tuple = list(map(tuple, data_edge_list)) #convert to (node1,node2) tuples.\n",
    "# and add edges to the graph\n",
    "G.add_edges_from(data_tuple)\n",
    "\n",
    "\n",
    "NODE_FDIM = data_node_features.shape[1]\n",
    "# update the nodes by adding node attributes\n",
    "for i in range(data_node_labels.shape[0]):\n",
    "    G.add_node(i, feature = data_node_features[i])\n",
    "    G.add_node(i, label = data_node_labels[i])\n",
    "\n",
    "EDGE_FDIM = data_edge_features.shape[1]\n",
    "# update the edges by adding edge attributes\n",
    "for i in range(data_edge_features.shape[0]):\n",
    "    u,v = data_tuple[i]\n",
    "    G.add_edge(u,v, feature = data_edge_features[i])\n",
    "    \n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "# split into each graphs\n",
    "graph_num = data_graph_indicator.max()+1\n",
    "node_list = np.arange(data_graph_indicator.shape[0])\n",
    "\n",
    "all_graphs = []\n",
    "for i in range(graph_num):\n",
    "    # find the nodes for each graph\n",
    "    nodes = node_list[data_graph_indicator==i]\n",
    "    #print('nodes = ',nodes)\n",
    "    G_sub = G.subgraph(nodes)\n",
    "    G_sub.graph['label'] = data_graph_labels[i]\n",
    "    all_graphs.append(G_sub)\n",
    "\n",
    "#print each graph\n",
    "print('Printing the graphs read ------------------>')\n",
    "for i,gr in enumerate(all_graphs):\n",
    "    print('graph ',i,', no of nodes:',gr.number_of_nodes())\n",
    "    print('adjacency_list:')\n",
    "    for n, nbrdict in gr.adjacency():\n",
    "        print(n,'=',nbrdict)\n",
    "    print('adjacency_matrix = \\n',nx.to_numpy_matrix(gr)) #adjacency matrix\n",
    "    node_features = nx.get_node_attributes(gr, 'feature')\n",
    "    node_labels = nx.get_node_attributes(gr, 'label')\n",
    "\n",
    "    for nd in gr.nodes():\n",
    "        print('node',nd,'features=',node_features[nd],'label=',node_labels[nd])\n",
    "\n",
    "    edge_features = nx.get_edge_attributes(gr,'feature') \n",
    "    for k,ee in enumerate(gr.edges()):\n",
    "        print('edge',ee,'features=',edge_features[ee])\n",
    "    print('----------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "#Create a torch DataLoader object using the graph data read above.\n",
    "class GraphSet(Dataset):\n",
    "    \n",
    "    def __init__(self,all_graphs):\n",
    "        self.all_graphs = all_graphs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_graphs)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.all_graphs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def index_select_ND(message, dim, index_matrix):\n",
    "    # say message is of shape [a,c] 89,5\n",
    "    # say index_matrix is of shape [a,b] 89,6\n",
    "    # to select the entries from message indexed by index_matrix entries.\n",
    "    index_size = index_matrix.size()  # say index_size = [a,b]  \n",
    "    suffix_dim = message.size()[1:]   # suffix_dim = [c]\n",
    "    final_size = index_size + suffix_dim # final_size = [a,b,c] = 89 6 5\n",
    "    index_matrix_flat = index_matrix.view(-1) # flatten the index to 1-dim tensor of shape = [ab]. 89*6\n",
    "    # use index_matrix_flat to index into message, i.e., select ab entries from [a,c]\n",
    "    # this is possible as the indices are repeated.\n",
    "    selected = message.index_select(dim, index_matrix_flat) # selected has shape [ab,c]  \n",
    "    selected_reshaped = selected.view(final_size) #reshape tensor to [a,b,c]\n",
    "    return selected_reshaped\n",
    "\n",
    "\n",
    "def process_all_graphs(all_graphs, node_fdim, edge_fdim):\n",
    "    \n",
    "    padding = torch.zeros(node_fdim + edge_fdim)\n",
    "    fnodes = []\n",
    "    fedges = [padding] #Ensure edges are 1-indexed, i.e entry 0 is dummy [000...0]\n",
    "\n",
    "    edge_indices = []\n",
    "    all_edges = [(-1,-1)] #Ensure edges are 1-indexed, entry 0 is dummay [(-1,-1)]\n",
    " \n",
    "    scope = [] # start and no. of nodes of each graph in all_graphs\n",
    "    total_nodes = 0\n",
    "    MAX_NBR = 0\n",
    "\n",
    "    for i,gr in enumerate(all_graphs):\n",
    "\n",
    "        #get the node and edge features for this graph.\n",
    "        node_features = nx.get_node_attributes(gr, 'feature')\n",
    "        edge_features = nx.get_edge_attributes(gr,'feature') \n",
    "        num_nodes = gr.number_of_nodes()\n",
    "        #print('graph',i,' has #nodes = ',num_nodes)\n",
    "        \n",
    "        for a_node in gr.nodes():\n",
    "            num_nbr = len(gr[a_node])\n",
    "            MAX_NBR = num_nbr if num_nbr>MAX_NBR else MAX_NBR        \n",
    "            nf = torch.Tensor(node_features[a_node]) \n",
    "            fnodes.append(nf) #one-hot encoded node features.\n",
    "            edge_indices.append([])\n",
    "\n",
    "        for ne, an_edge in enumerate(gr.edges):\n",
    "            x,y = an_edge\n",
    "            #print('EDGE : ',x,y)\n",
    "            bf = torch.Tensor(edge_features[an_edge])\n",
    "\n",
    "            b = len(all_edges)\n",
    "            all_edges.append((x,y))\n",
    "            fedges.append( torch.cat([fnodes[x], bf], 0) )\n",
    "            edge_indices[y].append(b)\n",
    "\n",
    "            b = len(all_edges)\n",
    "            all_edges.append((y,x))\n",
    "            fedges.append( torch.cat([fnodes[y], bf], 0) )\n",
    "            edge_indices[x].append(b)\n",
    "            \n",
    "        scope.append((total_nodes,num_nodes))\n",
    "        total_nodes += num_nodes\n",
    "\n",
    "    total_edges = len(all_edges)\n",
    "    fnodes = torch.stack(fnodes, 0)\n",
    "    fedges = torch.stack(fedges, 0)\n",
    "    nodes_graph = torch.zeros(total_nodes,MAX_NBR).long()\n",
    "    edges_graph = torch.zeros(total_edges,MAX_NBR).long()\n",
    "\n",
    "    # nodes_graph[y,:] : for each node y : indices of all edges (z,y) in all_edges\n",
    "    for a in range(total_nodes):\n",
    "        for i,b in enumerate(edge_indices[a]):\n",
    "            nodes_graph[a,i] = b\n",
    "\n",
    "    # say all_edges[i] holds edge (x,y)\n",
    "    # then edge_indices[i] holds indices for edges (_,x)\n",
    "    # then, edges_graph[i] : indices of all edges (_,x) excluding (y,x) \n",
    "    for b1 in range(1, total_edges):\n",
    "        x,y = all_edges[b1]\n",
    "        for i,b2 in enumerate(edge_indices[x]):\n",
    "            if all_edges[b2][0] != y:\n",
    "                edges_graph[b1,i] = b2\n",
    "\n",
    "    return fnodes,fedges,nodes_graph,edges_graph,scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, depth):\n",
    "        super(Graph_Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.depth = depth\n",
    "\n",
    "        self.W_i = nn.Linear(NODE_FDIM + EDGE_FDIM, hidden_size, bias=False)\n",
    "        self.W_h = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.W_o = nn.Linear(NODE_FDIM + hidden_size, hidden_size)\n",
    "\n",
    "        \n",
    "    def forward(self, GRAPHS):\n",
    "        fnodes,fedges,nodes_graph,edges_graph,scope = GRAPHS\n",
    "        fnodes = Variable(fnodes,requires_grad=False).cuda()\n",
    "        fedges = Variable(fedges,requires_grad=False).cuda()\n",
    "        nodes_graph = Variable(nodes_graph,requires_grad=False).cuda()\n",
    "        edges_graph = Variable(edges_graph,requires_grad=False).cuda()\n",
    "\n",
    "        binput = self.W_i(fedges) # no_edges x hidden_size\n",
    "        message = nn.ReLU()(binput) # no_edges x hidden_size\n",
    "\n",
    "        #Starting to loop, is this the loopy belief propagation ?\n",
    "        for i in range(self.depth - 1):\n",
    "            #get the message vectors for each edge in a no_edges x MAX_NBR x hidden_size tensor.\n",
    "            nei_message = index_select_ND(message, 0, edges_graph)\n",
    "            nei_message = nei_message.sum(dim=1)\n",
    "            nei_message = self.W_h(nei_message)\n",
    "            message = nn.ReLU()(binput + nei_message)\n",
    "\n",
    "        nei_message = index_select_ND(message, 0, nodes_graph)\n",
    "        nei_message = nei_message.sum(dim=1)\n",
    "        ainput = torch.cat([fnodes, nei_message], dim=1)\n",
    "        #hidden states for each node, size = no_of_nodes x hidden_size\n",
    "        nodes_hidden_states = nn.ReLU()(self.W_o(ainput))\n",
    "\n",
    "        graph_vecs = []\n",
    "        #scope = (start,len)\n",
    "        for start,length in scope:\n",
    "            #select the hidden states of all nodes for each graph and get mean hidden state\n",
    "            node_mean_vec = nodes_hidden_states.narrow(0, start, length).sum(dim=0) / length\n",
    "            graph_vecs.append(node_mean_vec)\n",
    "\n",
    "        graph_vecs = torch.stack(graph_vecs, dim=0)\n",
    "        return graph_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got encoded graph_vec = \n",
      " torch.Size([2, 64]) \n",
      " tensor([[0.1968, 0.4424, 0.1001, 0.2686, 0.0000, 0.3733, 0.0000, 0.0000, 0.1458,\n",
      "         0.0000, 0.0000, 0.0000, 0.6756, 0.7434, 0.0000, 0.4002, 0.1905, 0.0000,\n",
      "         0.0000, 0.0000, 0.8678, 0.0352, 1.0625, 0.1922, 0.0649, 0.2291, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0075, 0.9274, 0.0000, 0.5980, 0.0000, 0.0763,\n",
      "         0.0737, 0.3938, 1.0717, 0.5079, 0.8683, 0.0637, 0.0000, 0.6901, 0.0437,\n",
      "         0.0000, 0.0370, 0.1469, 0.4368, 0.0829, 0.5535, 0.5256, 0.7151, 0.4617,\n",
      "         0.6806, 0.7576, 0.4251, 0.0567, 0.3271, 0.3759, 0.3475, 0.4195, 1.5040,\n",
      "         0.5318],\n",
      "        [0.1187, 0.3034, 0.2118, 0.0000, 0.0000, 0.1631, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.3917, 0.3852, 0.0000, 0.5183, 0.0762, 0.0000,\n",
      "         0.0000, 0.0000, 0.7842, 0.1063, 0.8461, 0.3131, 0.1856, 0.1307, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.5902, 0.0000, 0.4130, 0.0000, 0.0451,\n",
      "         0.0000, 0.4720, 0.7019, 0.6078, 0.4780, 0.2884, 0.0000, 0.7106, 0.0352,\n",
      "         0.0000, 0.0200, 0.1436, 0.6309, 0.2144, 0.5776, 0.2388, 0.6554, 0.1765,\n",
      "         0.2202, 0.5668, 0.3902, 0.1708, 0.4845, 0.3577, 0.3217, 0.4110, 1.0298,\n",
      "         0.3787]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 64\n",
    "depth = 8\n",
    "model_graph_encoder = Graph_Encoder(hidden_size, depth).cuda() #the Graph_Encoder model\n",
    "graph_dataset =  GraphSet(all_graphs) #dataset\n",
    "\n",
    "#prepare a dummy batch to see how a single batch of graph encodings is generated.\n",
    "batch = []\n",
    "batch.append(graph_dataset[0])\n",
    "batch.append(graph_dataset[1]) # batch_size = 2\n",
    "\n",
    "#convert the batch of graphs to [fnodes,fedges,nodes_graph,edges_graph,scope] for passing thru Graph_Encoder.\n",
    "GRAPHS = process_all_graphs(batch, NODE_FDIM,EDGE_FDIM)\n",
    "graph_vec = model_graph_encoder(GRAPHS)\n",
    "print('Got encoded graph_vec = \\n',graph_vec.data.shape,'\\n',graph_vec.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
