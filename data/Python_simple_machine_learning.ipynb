{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\u588401\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: python-dateutil>=2 in c:\\users\\u588401\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\u588401\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\u588401\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\u588401\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from python-dateutil>=2->pandas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets start with installing pandas from within python interactive shell. This may be needed if you are missing a package.\n",
    "import pip\n",
    "#if you have pip installed, you can use this to install any package you need : pip.main(['install',package-name])\n",
    "pip.main(['install','pandas']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use pandas to load the dataset from a url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape= (149, 5)\n",
      "   5.1  3.5  1.4  0.2  Iris-setosa\n",
      "0  4.9  3.0  1.4  0.2  Iris-setosa\n",
      "1  4.7  3.2  1.3  0.2  Iris-setosa\n",
      "2  4.6  3.1  1.5  0.2  Iris-setosa\n",
      "3  5.0  3.6  1.4  0.2  Iris-setosa\n",
      "4  5.4  3.9  1.7  0.4  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "dataset = pandas.read_csv(url)\n",
    "print('shape=',dataset.shape)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Oh no, the dataset has no column names, lets add them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D            E\n",
      "0  4.9  3.0  1.4  0.2  Iris-setosa\n",
      "1  4.7  3.2  1.3  0.2  Iris-setosa\n",
      "2  4.6  3.1  1.5  0.2  Iris-setosa\n",
      "3  5.0  3.6  1.4  0.2  Iris-setosa\n",
      "4  5.4  3.9  1.7  0.4  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "dataset.columns=['A','B','C','D','E']\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the class distribution of the column we will use as target for our machine learning tasks, column 'E'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "Iris-setosa        49\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.groupby('E').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets split our dataset randomly into training, testing, and validation datasets. First, shuffle the dataset randomly with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A    B    C    D                E\n",
      "9    5.4  3.7  1.5  0.2      Iris-setosa\n",
      "113  5.8  2.8  5.1  2.4   Iris-virginica\n",
      "96   6.2  2.9  4.3  1.3  Iris-versicolor\n",
      "118  6.0  2.2  5.0  1.5   Iris-virginica\n",
      "147  6.2  3.4  5.4  2.3   Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "# The frac keyword argument specifies the fraction of rows to return in\n",
    "# the random sample, so frac=1 means return all rows (in random order).\n",
    "dataset_shuffled = dataset.sample(frac=1)\n",
    "print(dataset_shuffled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split the data into training and validation sets in 80:20 ratio. We will use the validation set to test the \n",
    "performance of machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = dataset_shuffled.shape[0]\n",
    "validation_size = int(0.2*n)\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "data_array = dataset_shuffled.values\n",
    "X = data_array[:,0:4]  # separate the predictor variables\n",
    "Y = data_array[:,4]    # from the target variable (last column)\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X,Y,test_size=validation_size,random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the sizes of the training and validation data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_X =  (120, 4) Train_Y =  (120,)\n",
      "Val_X =  (29, 4) Val_Y =  (29,)\n"
     ]
    }
   ],
   "source": [
    "print('Train_X = ',X_train.shape, 'Train_Y = ',Y_train.shape)\n",
    "print('Val_X = ',X_validation.shape, 'Val_Y = ',Y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression  :  [1.0, 1.0, 1.0, 0.6666666666666666, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 1.0]\n",
      "LogisticRegression  : mean= 0.9333333333333333  sd= 0.10540925533894599\n",
      "------------------------------------------------------------------------\n",
      "KNeighborsClassifier  :  [1.0, 0.9333333333333333, 1.0, 0.8666666666666667, 1.0, 0.9333333333333333, 1.0, 1.0]\n",
      "KNeighborsClassifier  : mean= 0.9666666666666667  sd= 0.04714045207910316\n",
      "------------------------------------------------------------------------\n",
      "DecisionTreeClassifier  :  [0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 1.0, 0.9333333333333333, 1.0, 0.9333333333333333]\n",
      "DecisionTreeClassifier  : mean= 0.95  sd= 0.02886751345948128\n",
      "------------------------------------------------------------------------\n",
      "SVC  :  [0.9333333333333333, 1.0, 0.9333333333333333, 0.9333333333333333, 1.0, 0.9333333333333333, 1.0, 1.0]\n",
      "SVC  : mean= 0.9666666666666667  sd= 0.033333333333333326\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "\n",
    "# we will use these classifiers\n",
    "LR = linear_model.LogisticRegression()\n",
    "KNN = neighbors.KNeighborsClassifier()\n",
    "DT = tree.DecisionTreeClassifier()\n",
    "SVM = svm.SVC()\n",
    "\n",
    "models_list = [LR,KNN,DT,SVM]\n",
    "num_folds = 8\n",
    "kfolds = model_selection.KFold(n_splits=num_folds, shuffle=True, random_state=13)\n",
    "for model in models_list:\n",
    "    model_name = type(model).__name__\n",
    "    cv_results = model_selection.cross_val_score(model,X_train,Y_train,scoring='accuracy',cv=kfolds)\n",
    "    print(model_name,' : ',cv_results.tolist())\n",
    "    print(model_name,' : mean=',cv_results.mean(), ' sd=',cv_results.std())\n",
    "    print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is naive training with each of the classifiers as we have not done anything to optimize the parameters for each classifer. We will use sklearn.model_selection.GridSearchCV for that. Lets do this with each classifier separately because each classifier will have its own set of parametes to tune. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = model_selection.KFold(n_splits=num_folds,shuffle=True,random_state=13)\n",
    "\n",
    "#define function to be called to do grid search for each of the classifiers.\n",
    "\n",
    "def print_cv_results(estimator,results):\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    print(type(estimator).__name__)\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print('best_parameters=',results.best_params_)\n",
    "    print('best_accuracy=',results.best_score_)\n",
    "    print('----------------------------------------------')\n",
    "    \n",
    "def do_grid_search(estimator,grid_values,kfolds):\n",
    "    clf = model_selection.GridSearchCV(estimator=estimator,param_grid=grid_values,scoring='accuracy',cv=kfolds)\n",
    "    results = clf.fit(X_train,Y_train)\n",
    "    print_cv_results(estimator,results)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "0.233 (+/-0.149) for {'C': 0.01, 'penalty': 'l1'}\n",
      "0.675 (+/-0.356) for {'C': 0.01, 'penalty': 'l2'}\n",
      "0.725 (+/-0.380) for {'C': 0.1, 'penalty': 'l1'}\n",
      "0.817 (+/-0.420) for {'C': 0.1, 'penalty': 'l2'}\n",
      "0.950 (+/-0.088) for {'C': 1, 'penalty': 'l1'}\n",
      "0.933 (+/-0.211) for {'C': 1, 'penalty': 'l2'}\n",
      "0.967 (+/-0.094) for {'C': 10, 'penalty': 'l1'}\n",
      "0.967 (+/-0.094) for {'C': 10, 'penalty': 'l2'}\n",
      "0.958 (+/-0.093) for {'C': 100, 'penalty': 'l1'}\n",
      "0.967 (+/-0.094) for {'C': 100, 'penalty': 'l2'}\n",
      "best_parameters= {'C': 10, 'penalty': 'l1'}\n",
      "best_accuracy= 0.9666666666666667\n",
      "----------------------------------------------\n",
      "KNeighborsClassifier\n",
      "0.958 (+/-0.065) for {'n_neighbors': 1}\n",
      "0.950 (+/-0.058) for {'n_neighbors': 2}\n",
      "0.958 (+/-0.065) for {'n_neighbors': 3}\n",
      "0.967 (+/-0.067) for {'n_neighbors': 4}\n",
      "0.967 (+/-0.094) for {'n_neighbors': 5}\n",
      "0.975 (+/-0.065) for {'n_neighbors': 6}\n",
      "0.975 (+/-0.065) for {'n_neighbors': 7}\n",
      "0.975 (+/-0.065) for {'n_neighbors': 8}\n",
      "0.975 (+/-0.065) for {'n_neighbors': 9}\n",
      "best_parameters= {'n_neighbors': 6}\n",
      "best_accuracy= 0.975\n",
      "----------------------------------------------\n",
      "DecisionTreeClassifier\n",
      "0.942 (+/-0.080) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "0.942 (+/-0.104) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "0.942 (+/-0.080) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "0.950 (+/-0.088) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 3, 'splitter': 'random'}\n",
      "0.942 (+/-0.080) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'splitter': 'best'}\n",
      "0.975 (+/-0.065) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "0.942 (+/-0.080) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "0.900 (+/-0.115) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "0.933 (+/-0.094) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "0.925 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 6, 'splitter': 'random'}\n",
      "0.942 (+/-0.080) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "0.967 (+/-0.067) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 7, 'splitter': 'random'}\n",
      "0.933 (+/-0.115) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "0.942 (+/-0.080) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 8, 'splitter': 'random'}\n",
      "0.933 (+/-0.115) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "0.925 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 9, 'splitter': 'random'}\n",
      "0.942 (+/-0.080) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "0.958 (+/-0.093) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "0.933 (+/-0.094) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "0.925 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 3, 'splitter': 'random'}\n",
      "0.942 (+/-0.080) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 4, 'splitter': 'best'}\n",
      "0.917 (+/-0.111) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "0.933 (+/-0.094) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "0.975 (+/-0.065) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "0.933 (+/-0.094) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "0.925 (+/-0.155) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 6, 'splitter': 'random'}\n",
      "0.942 (+/-0.080) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "0.967 (+/-0.067) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 7, 'splitter': 'random'}\n",
      "0.933 (+/-0.115) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "0.917 (+/-0.111) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 8, 'splitter': 'random'}\n",
      "0.933 (+/-0.115) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "0.958 (+/-0.093) for {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 9, 'splitter': 'random'}\n",
      "0.967 (+/-0.067) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "0.933 (+/-0.149) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "0.967 (+/-0.067) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "0.958 (+/-0.093) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 3, 'splitter': 'random'}\n",
      "0.958 (+/-0.065) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 4, 'splitter': 'best'}\n",
      "0.917 (+/-0.173) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "0.967 (+/-0.067) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "0.958 (+/-0.093) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "0.950 (+/-0.088) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "0.925 (+/-0.104) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 6, 'splitter': 'random'}\n",
      "0.958 (+/-0.065) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "0.933 (+/-0.094) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 7, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "0.908 (+/-0.132) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 8, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "0.942 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 9, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "0.950 (+/-0.088) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "0.908 (+/-0.114) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 4, 'splitter': 'best'}\n",
      "0.933 (+/-0.094) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "0.950 (+/-0.058) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "0.933 (+/-0.067) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 6, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "0.875 (+/-0.294) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 7, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "0.942 (+/-0.104) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 8, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "0.933 (+/-0.163) for {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 9, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "0.875 (+/-0.194) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "0.900 (+/-0.231) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 3, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'splitter': 'best'}\n",
      "0.925 (+/-0.104) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "0.900 (+/-0.149) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "0.925 (+/-0.155) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 6, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "0.900 (+/-0.094) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 7, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "0.900 (+/-0.163) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 8, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "0.917 (+/-0.160) for {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 9, 'splitter': 'random'}\n",
      "0.933 (+/-0.094) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "0.942 (+/-0.080) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "0.942 (+/-0.104) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "0.892 (+/-0.114) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 3, 'splitter': 'random'}\n",
      "0.933 (+/-0.094) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'splitter': 'best'}\n",
      "0.933 (+/-0.133) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "0.942 (+/-0.104) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "0.933 (+/-0.094) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "0.942 (+/-0.104) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "0.942 (+/-0.104) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 6, 'splitter': 'random'}\n",
      "0.950 (+/-0.088) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "0.942 (+/-0.104) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 7, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "0.942 (+/-0.080) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 8, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "0.917 (+/-0.160) for {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 9, 'splitter': 'random'}\n",
      "0.942 (+/-0.080) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "0.958 (+/-0.065) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "0.942 (+/-0.080) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "0.958 (+/-0.065) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 3, 'splitter': 'random'}\n",
      "0.942 (+/-0.080) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 4, 'splitter': 'best'}\n",
      "0.925 (+/-0.104) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "0.933 (+/-0.094) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "0.958 (+/-0.093) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "0.942 (+/-0.104) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "0.942 (+/-0.169) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 6, 'splitter': 'random'}\n",
      "0.950 (+/-0.088) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "0.942 (+/-0.104) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 7, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "0.950 (+/-0.058) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 8, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "0.950 (+/-0.111) for {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 9, 'splitter': 'random'}\n",
      "0.950 (+/-0.088) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "0.950 (+/-0.111) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "0.950 (+/-0.088) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "0.900 (+/-0.189) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 3, 'splitter': 'random'}\n",
      "0.958 (+/-0.065) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 4, 'splitter': 'best'}\n",
      "0.933 (+/-0.094) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "0.950 (+/-0.088) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "0.925 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "0.958 (+/-0.065) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "0.908 (+/-0.210) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 6, 'splitter': 'random'}\n",
      "0.958 (+/-0.065) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "0.908 (+/-0.132) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 7, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "0.925 (+/-0.104) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 8, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "0.908 (+/-0.162) for {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 9, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "0.950 (+/-0.088) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "0.950 (+/-0.058) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 4, 'splitter': 'best'}\n",
      "0.950 (+/-0.088) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "0.942 (+/-0.104) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "0.933 (+/-0.115) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 6, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "0.933 (+/-0.133) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 7, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "0.942 (+/-0.080) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 8, 'splitter': 'random'}\n",
      "0.942 (+/-0.124) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "0.908 (+/-0.148) for {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 9, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "0.958 (+/-0.065) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "0.917 (+/-0.088) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 3, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'splitter': 'best'}\n",
      "0.950 (+/-0.088) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "0.950 (+/-0.088) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 6, 'splitter': 'best'}\n",
      "0.900 (+/-0.115) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 6, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 7, 'splitter': 'best'}\n",
      "0.908 (+/-0.114) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 7, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "0.925 (+/-0.080) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 8, 'splitter': 'random'}\n",
      "0.950 (+/-0.129) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 9, 'splitter': 'best'}\n",
      "0.925 (+/-0.104) for {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 9, 'splitter': 'random'}\n",
      "best_parameters= {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'splitter': 'random'}\n",
      "best_accuracy= 0.975\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# First, logistic Regression parameters to tune : C, penalty\n",
    "grid_values = {'C':[0.01,0.1,1,10,100],'penalty':['l1','l2']}\n",
    "clf_LR = do_grid_search(LR,grid_values,kfolds) \n",
    "\n",
    "# Next we do with KNN\n",
    "grid_values = {'n_neighbors':list(range(1,10))}\n",
    "clf_KNN = do_grid_search(KNN,grid_values,kfolds)\n",
    "\n",
    "# Next Decision Tree\n",
    "grid_values = {'criterion':['gini','entropy'],'splitter':['best','random'],'min_samples_split':list(range(2,10)),'min_samples_leaf':[1,2,3,4,5]}\n",
    "clf_DT = do_grid_search(DT,grid_values,kfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "0.975 (+/-0.065) for {'C': 1, 'kernel': 'linear'}\n",
      "0.958 (+/-0.093) for {'C': 1, 'kernel': 'poly'}\n",
      "0.967 (+/-0.067) for {'C': 1, 'kernel': 'rbf'}\n",
      "0.192 (+/-0.140) for {'C': 1, 'kernel': 'sigmoid'}\n",
      "0.967 (+/-0.094) for {'C': 10, 'kernel': 'linear'}\n",
      "0.950 (+/-0.088) for {'C': 10, 'kernel': 'poly'}\n",
      "0.967 (+/-0.094) for {'C': 10, 'kernel': 'rbf'}\n",
      "0.192 (+/-0.140) for {'C': 10, 'kernel': 'sigmoid'}\n",
      "0.958 (+/-0.093) for {'C': 100, 'kernel': 'linear'}\n",
      "0.942 (+/-0.080) for {'C': 100, 'kernel': 'poly'}\n",
      "0.942 (+/-0.104) for {'C': 100, 'kernel': 'rbf'}\n",
      "0.192 (+/-0.140) for {'C': 100, 'kernel': 'sigmoid'}\n",
      "best_parameters= {'C': 1, 'kernel': 'linear'}\n",
      "best_accuracy= 0.975\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# And finally SVM\n",
    "grid_values = {'C':[1,10,100],'kernel':['linear', 'poly', 'rbf', 'sigmoid'] }\n",
    "clf_SVM = do_grid_search(SVM,grid_values,kfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       1.00      1.00      1.00         9\n",
      " Iris-virginica       1.00      1.00      1.00        10\n",
      "\n",
      "    avg / total       1.00      1.00      1.00        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# predictions for LR\n",
    "Y_true, Y_pred = Y_validation, clf_LR.predict(X_validation)\n",
    "print(classification_report(Y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       0.90      1.00      0.95         9\n",
      " Iris-virginica       1.00      0.90      0.95        10\n",
      "\n",
      "    avg / total       0.97      0.97      0.97        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions for KNN\n",
    "Y_true, Y_pred = Y_validation, clf_KNN.predict(X_validation)\n",
    "print(classification_report(Y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       0.82      1.00      0.90         9\n",
      " Iris-virginica       1.00      0.80      0.89        10\n",
      "\n",
      "    avg / total       0.94      0.93      0.93        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions for DT\n",
    "Y_true, Y_pred = Y_validation, clf_DT.predict(X_validation)\n",
    "print(classification_report(Y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       0.90      1.00      0.95         9\n",
      " Iris-virginica       1.00      0.90      0.95        10\n",
      "\n",
      "    avg / total       0.97      0.97      0.97        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions for SVM\n",
    "Y_true, Y_pred = Y_validation, clf_SVM.predict(X_validation)\n",
    "print(classification_report(Y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
