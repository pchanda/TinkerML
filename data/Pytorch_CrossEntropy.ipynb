{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "capital-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-carpet",
   "metadata": {},
   "source": [
    "### Cross entropy with 4 outputs and a target class.\n",
    "\n",
    "logits tensor has shape `batch_size` x `num_outputs`. Here `batch_size`=1, `num_outputs`=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "spatial-april",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits= torch.Size([1, 4]) \n",
      " tensor([[ 4.,  3.,  2., 10.]])\n",
      "\n",
      "Target= tensor([3])\n",
      "\n",
      "loss= tensor([0.0037])\n"
     ]
    }
   ],
   "source": [
    "ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "logits = torch.from_numpy(np.array([[4, 3, 2, 10]])).float()\n",
    "print('Logits=',logits.shape,'\\n',logits)\n",
    "\n",
    "target_class = 3\n",
    "target_class_tensor = torch.from_numpy(np.array([target_class]))\n",
    "print('\\nTarget=',target_class_tensor)\n",
    "loss = ce_loss(logits, target_class_tensor)\n",
    "print('\\nloss=',loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-editing",
   "metadata": {},
   "source": [
    "You can get the probabilities from logits by using softmax. \n",
    "Then negative log of the probability of the target class is the CE loss, same as above. The loss is close to 0 \n",
    "as the logit corresponding to (correct) target class 3 is much higher compared to the logits of other target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "recognized-hughes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilities= torch.Size([1, 4])\n",
      "tensor([[2.4696e-03, 9.0850e-04, 3.3422e-04, 9.9629e-01]])\n",
      "CE loss= tensor([0.0037])\n"
     ]
    }
   ],
   "source": [
    "probabilities = nn.functional.softmax(logits,dim=1)\n",
    "target_class = torch.from_numpy(np.array([3]))\n",
    "print('\\nProbabilities=',probabilities.shape)\n",
    "print(probabilities)\n",
    "\n",
    "print('CE loss=',-np.log(torch.squeeze(probabilities)[target_class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-hollywood",
   "metadata": {},
   "source": [
    "### Cross entropy with 4 outputs and a target class. Each output is a 2D tensor.\n",
    "\n",
    "logits tensor has shape `batch_size` x `num_outputs` x `2`. Here batch_size=1, num_outputs=4\n",
    "\n",
    "The loss is very high as the logit corresponding to target class 3 is low. The highest logit\n",
    "corresponds to the target class 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "found-words",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits torch.Size([1, 4]) \n",
      " tensor([[20.,  2.,  3.,  4.]])\n",
      "\n",
      "Probabilities= torch.Size([1, 4])\n",
      "tensor([[1.0000e+00, 1.5230e-08, 4.1399e-08, 1.1254e-07]])\n",
      "Target torch.Size([1]) \n",
      " tensor([3])\n",
      "\n",
      "loss= tensor([16.])\n"
     ]
    }
   ],
   "source": [
    "ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "logits = torch.from_numpy(np.array([[20, 2, 3, 4]])).float()\n",
    "print('Logits',logits.shape,'\\n',logits)\n",
    "probabilities = nn.functional.softmax(logits,dim=1)\n",
    "target_classes = torch.from_numpy(np.array([3]))\n",
    "print('\\nProbabilities=',probabilities.shape)\n",
    "print(probabilities)\n",
    "print('Target',target_classes.shape,'\\n',target_classes)\n",
    "loss = ce_loss(logits, target_classes)\n",
    "print('\\nloss=',loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-contribution",
   "metadata": {},
   "source": [
    "### Cross entropy with 4 outputs and a target class. Each output is a 2D tensor.\n",
    "\n",
    "logits tensor has shape `batch_size` x `num_outputs` x `2`. Here batch_size=1, num_outputs=4. \n",
    "The loss tensor will have dimensionality of 2 - one loss for each of the 2 dimensions of the output (as we have reduction=`none`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "opponent-drain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits torch.Size([1, 4, 2]) \n",
      " tensor([[[ 4., 10.],\n",
      "         [ 3.,  2.],\n",
      "         [ 2.,  3.],\n",
      "         [10.,  4.]]])\n",
      "\n",
      "Target torch.Size([1, 2]) \n",
      " tensor([[3, 1]])\n",
      "\n",
      "loss= tensor([[3.7192e-03, 8.0037e+00]])\n"
     ]
    }
   ],
   "source": [
    "ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "logits = torch.from_numpy(np.array([[[4,10], [3,2], [2,3], [10,4]]])).float()\n",
    "print('Logits',logits.shape,'\\n',logits)\n",
    "\n",
    "#Target classes for each dimension of the output.\n",
    "target_classes = torch.from_numpy(np.array([[3,1]]))\n",
    "print('\\nTarget',target_classes.shape,'\\n',target_classes)\n",
    "\n",
    "loss = ce_loss(logits, target_classes)\n",
    "print('\\nloss=',loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-mainstream",
   "metadata": {},
   "source": [
    "### Cross entropy with 4 outputs and a target class (batch_size=2). Each output is a 2D tensor.\n",
    "\n",
    "logits tensor has shape `batch_size` x `num_outputs` x `2`. Here batch_size=2, num_outputs=4. \n",
    "The loss tensor will have dimensionality of 2 - one loss for each of the 2 dimensions of the output \n",
    "(as we have reduction=`none`). This is repeated for each of the 2 elements of the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "oriental-conversion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits torch.Size([2, 4, 2]) \n",
      " tensor([[[ 4.,  4.],\n",
      "         [ 3.,  3.],\n",
      "         [ 2.,  2.],\n",
      "         [ 2., 20.]],\n",
      "\n",
      "        [[20., 20.],\n",
      "         [ 3.,  3.],\n",
      "         [ 2.,  2.],\n",
      "         [10., 10.]]])\n",
      "torch.Size([2, 2]) \n",
      " tensor([[3, 3],\n",
      "        [0, 0]])\n",
      "\n",
      "loss= tensor([[2.4938e+00, 1.1921e-07],\n",
      "        [4.5418e-05, 4.5418e-05]])\n"
     ]
    }
   ],
   "source": [
    "ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "logits = torch.from_numpy(np.array([[[4,4], [3,3], [2,2], [2,20]], [[20,20], [3,3], [2,2], [10,10]]])).float()\n",
    "\n",
    "print('Logits',logits.shape,'\\n',logits)\n",
    "\n",
    "target_classes = torch.from_numpy(np.array([[3,3],[0,0]]))\n",
    "\n",
    "print(target_classes.shape,'\\n',target_classes)\n",
    "\n",
    "loss = ce_loss(logits, target_classes)\n",
    "print('\\nloss=',loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
